{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madrid's Air Quality Analysis (2018-2019)\n",
    "\n",
    "Throughout the following Jupyter Notebook you're going to analyze the **air quality in Madrid** from **January 2018** to **November 2019**, by using the **Spark skills** you've learned during the **Spark Course**.\n",
    "\n",
    "Data set used is coming from the [Madrid Town's Open Data Portal](https://datos.madrid.es/), specifically, from the [Real-time Air Quality](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=41e01e007c9db410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default) section. **Documentation on the data set is available** in this [link](https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global.pdf), although *it's in Spanish*. The document will be used as a reference and *translated as needed*.\n",
    "\n",
    "## 1. PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import upper, col\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data source and Spark data abstraction (DataFrame) setup\n",
    "To-do:\n",
    "- Download file `airqualitydata_madrid1819.zip` file from \"Additional Documentation\" to your laptop.\n",
    "- Unzip the downloaded file. This creates a folder called `airqualitydata` in your laptop containing *23 CSV files* (Dec'19 is not in there).\n",
    "- Create a folder (ex. `airqualitydata`) in Jupyter.\n",
    "- Go into that folder and upload the 23 files.\n",
    "- Create a **custom schema** manually to translate CSV files headers:\n",
    "  - PROVINCE => `IntegerType`\n",
    "  - TOWN => `IntegerType`\n",
    "  - STATION => `IntegerType`\n",
    "  - MAGNITUDE => `IntegerType`\n",
    "  - SAMPLING_LOCATION => `StringType`\n",
    "  - YEAR => `IntegerType`\n",
    "  - MONTH => `IntegerType`\n",
    "  - DAY => `IntegerType`\n",
    "  - H01 => `DoubleType`\n",
    "  - V01 => `StringType`\n",
    "  - H02 => `DoubleType`\n",
    "  - V02 => `StringType`\n",
    "  - H03 => `DoubleType`\n",
    "  - V03 => `StringType`\n",
    "  - H04 => `DoubleType`\n",
    "  - V04 => `StringType`\n",
    "  - H05 => `DoubleType`\n",
    "  - V05 => `StringType`\n",
    "  - H06 => `DoubleType`\n",
    "  - V06 => `StringType`\n",
    "  - H07 => `DoubleType`\n",
    "  - V07 => `StringType`\n",
    "  - H08 => `DoubleType`\n",
    "  - V08 => `StringType`\n",
    "  - H09 => `DoubleType`\n",
    "  - V09 => `StringType`\n",
    "  - H10 => `DoubleType`\n",
    "  - V10 => `StringType`\n",
    "  - H11 => `DoubleType`\n",
    "  - V11 => `StringType`\n",
    "  - H12 => `DoubleType`\n",
    "  - V12 => `StringType`\n",
    "  - H13 => `DoubleType`\n",
    "  - V13 => `StringType`\n",
    "  - H14 => `DoubleType`\n",
    "  - V14 => `StringType`\n",
    "  - H15 => `DoubleType`\n",
    "  - V15 => `StringType`\n",
    "  - H16 => `DoubleType`\n",
    "  - V16 => `StringType`\n",
    "  - H17 => `DoubleType`\n",
    "  - V17 => `StringType`\n",
    "  - H18 => `DoubleType`\n",
    "  - V18 => `StringType`\n",
    "  - H19 => `DoubleType`\n",
    "  - V19 => `StringType`\n",
    "  - H20 => `DoubleType`\n",
    "  - V20 => `StringType`\n",
    "  - H21 => `DoubleType`\n",
    "  - V21 => `StringType`\n",
    "  - H22 => `DoubleType`\n",
    "  - V22 => `StringType`\n",
    "  - H23 => `DoubleType`\n",
    "  - V23 => `StringType`\n",
    "  - H24 => `DoubleType`\n",
    "  - V24 => `StringType`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqSchema = StructType(\\\n",
    "                     [StructField(\"PROVINCE\", IntegerType(),True),\\\n",
    "                     StructField(\"TOWN\", IntegerType(),True),\\\n",
    "                     StructField(\"STATION\", IntegerType(),True),\\\n",
    "                     StructField(\"MAGNITUDE\", IntegerType(),True),\\\n",
    "                     StructField(\"SAMPLING_LOCATION\", StringType(),True),\\\n",
    "                     StructField(\"YEAR\", IntegerType(),True),\\\n",
    "                     StructField(\"MONTH\", IntegerType(),True),\\\n",
    "                     StructField(\"DAY\", IntegerType(),True),\\\n",
    "                     StructField(\"H01\", DoubleType(),True),\\\n",
    "                     StructField(\"V01\", StringType(),True),\\\n",
    "                     StructField(\"H02\", DoubleType(),True),\\\n",
    "                     StructField(\"V02\", StringType(),True),\\\n",
    "                     StructField(\"H03\", DoubleType(),True),\\\n",
    "                     StructField(\"V03\", StringType(),True),\\\n",
    "                     StructField(\"H04\", DoubleType(),True),\\\n",
    "                     StructField(\"V04\", StringType(),True),\\\n",
    "                     StructField(\"H05\", DoubleType(),True),\\\n",
    "                     StructField(\"V05\", StringType(),True),\\\n",
    "                     StructField(\"H06\", DoubleType(),True),\\\n",
    "                     StructField(\"V06\", StringType(),True),\\\n",
    "                     StructField(\"H07\", DoubleType(),True),\\\n",
    "                     StructField(\"V07\", StringType(),True),\\\n",
    "                     StructField(\"H08\", DoubleType(),True),\\\n",
    "                     StructField(\"V08\", StringType(),True),\\\n",
    "                     StructField(\"H09\", DoubleType(),True),\\\n",
    "                     StructField(\"V09\", StringType(),True),\\\n",
    "                     StructField(\"H10\", DoubleType(),True),\\\n",
    "                     StructField(\"V10\", StringType(),True),\\\n",
    "                     StructField(\"H11\", DoubleType(),True),\\\n",
    "                     StructField(\"V11\", StringType(),True),\\\n",
    "                     StructField(\"H12\", DoubleType(),True),\\\n",
    "                     StructField(\"V12\", StringType(),True),\\\n",
    "                     StructField(\"H13\", DoubleType(),True),\\\n",
    "                     StructField(\"V13\", StringType(),True),\\\n",
    "                     StructField(\"H14\", DoubleType(),True),\\\n",
    "                     StructField(\"V14\", StringType(),True),\\\n",
    "                     StructField(\"H15\", DoubleType(),True),\\\n",
    "                     StructField(\"V15\", StringType(),True),\\\n",
    "                     StructField(\"H16\", DoubleType(),True),\\\n",
    "                     StructField(\"V16\", StringType(),True),\\\n",
    "                     StructField(\"H17\", DoubleType(),True),\\\n",
    "                     StructField(\"V17\", StringType(),True),\\\n",
    "                     StructField(\"H18\", DoubleType(),True),\\\n",
    "                     StructField(\"V18\", StringType(),True),\\\n",
    "                     StructField(\"H19\", DoubleType(),True),\\\n",
    "                     StructField(\"V19\", StringType(),True),\\\n",
    "                     StructField(\"H20\", DoubleType(),True),\\\n",
    "                     StructField(\"V20\", StringType(),True),\\\n",
    "                     StructField(\"H21\", DoubleType(),True),\\\n",
    "                     StructField(\"V21\", StringType(),True),\\\n",
    "                     StructField(\"H22\", DoubleType(),True),\\\n",
    "                     StructField(\"V22\", StringType(),True),\\\n",
    "                     StructField(\"H23\", DoubleType(),True),\\\n",
    "                     StructField(\"V23\", StringType(),True),\\\n",
    "                     StructField(\"H24\", DoubleType(),True),\\\n",
    "                     StructField(\"V24\", StringType(),True),\\\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqDF = spark.read.schema(aqSchema).option(\"header\",\"true\").option(\"sep\", \";\").csv(\"../Session 8/Data/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the `read` method to create the DataFrame (called `aqDF`).\n",
    "- Display the first Row of the DataFrame and the number of rows in the DataFrame.\n",
    "\n",
    "\n",
    "Hints:\n",
    "- `read` method/function can handle multiple CSV files inside a folder at once (see [this](https://stackoverflow.com/questions/37639956/how-to-import-multiple-csv-files-in-a-single-load))\n",
    "- Pay attention to the columns delimiter. Fields are not always separated by commas and that has to be handled accordingly via options (see [this](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=csv#pyspark.sql.DataFrameReader.csv))\n",
    "- In the end you should get **56 fields/columns** and **105,050 rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PROVINCE=28, TOWN=79, STATION=4, MAGNITUDE=1, SAMPLING_LOCATION='28079004_1_38', YEAR=2019, MONTH=10, DAY=1, H01=10.0, V01='V', H02=10.0, V02='V', H03=9.0, V03='V', H04=9.0, V04='V', H05=9.0, V05='V', H06=9.0, V06='V', H07=9.0, V07='V', H08=12.0, V08='V', H09=15.0, V09='V', H10=19.0, V10='V', H11=16.0, V11='V', H12=13.0, V12='V', H13=10.0, V13='V', H14=8.0, V14='V', H15=6.0, V15='V', H16=7.0, V16='V', H17=7.0, V17='V', H18=7.0, V18='V', H19=7.0, V19='V', H20=7.0, V20='V', H21=7.0, V21='V', H22=8.0, V22='V', H23=8.0, V23='V', H24=9.0, V24='V')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aqDF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105050"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a DataFrame manually (call it `magnitudesDF`) with the contents in the table **\"Magnitudes, units and measurement techniques\"**, available in **page 5/Appendix II** from the [aforementioned documentation](https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+------+-----------+--------------------+\n",
      "|magnitudeId|       magnitudeName|formula|  unit|techniqueId|       techniqueName|\n",
      "+-----------+--------------------+-------+------+-----------+--------------------+\n",
      "|          1|     Sulphur dioxide|    SO2|ug/m^3|         38|Ultraviolet fluor...|\n",
      "|          6|     Carbon monoxide|    CO2|ug/m^3|         48| Infrared absorption|\n",
      "|          7|   Nitrogen monoxide|     NO|ug/m^3|          8|   Chemiluminescence|\n",
      "|          8|    Nitrogen dioxide|    NO2|ug/m^3|          8|                 Id.|\n",
      "|          9|           Particles|  PM2.5|ug/m^3|         47|Ultraviolet fluor...|\n",
      "|         10|           Particles|   PM10|ug/m^3|         47|                 Id.|\n",
      "|         12|     Nitrogen oxides|    NOx|ug/m^3|          8|Ultraviolet fluor...|\n",
      "|         14|               Ozone|     O3|ug/m^3|          6|Ultraviolet fluor...|\n",
      "|         20|             Toluene|    TOL|ug/m^3|         59|Ultraviolet fluor...|\n",
      "|         30|             Benzene|    BEN|ug/m^3|         59|                 Id.|\n",
      "|         35|        Ethylbenzene|    EBE|ug/m^3|         59|                 Id.|\n",
      "|         37|          Mexaxylene|    MXY|ug/m^3|         59|                 Id.|\n",
      "|         38|          Paraxylene|    PXY|ug/m^3|         59|                 Id.|\n",
      "|         39|         Orthoxylene|    OXY|ug/m^3|         59|                 Id.|\n",
      "|         42|Total hydrocarbon...|    TCH|ug/m^3|          2|Ultraviolet fluor...|\n",
      "|         43|             Methane|    CH4|ug/m^3|          2|                 Id.|\n",
      "|         44|Non-methane hydro...|   NMHC|ug/m^3|          2|                 Id.|\n",
      "+-----------+--------------------+-------+------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "magnitudes = [\n",
    "    Row(1, \"Sulphur dioxide\", \"SO2\", \"ug/m^3\", 38, \"Ultraviolet fluorescence\"),\n",
    "    Row(6, \"Carbon monoxide\", \"CO2\", \"ug/m^3\", 48, \"Infrared absorption\"),\n",
    "    Row(7, \"Nitrogen monoxide\", \"NO\", \"ug/m^3\", 8, \"Chemiluminescence\"),\n",
    "    Row(8, \"Nitrogen dioxide\", \"NO2\", \"ug/m^3\", 8, \"Id.\"),\n",
    "    Row(9, \"Particles\", \"PM2.5\", \"ug/m^3\", 47, \"Ultraviolet fluorescence\"),\n",
    "    Row(10, \"Particles\", \"PM10\", \"ug/m^3\", 47, \"Id.\"),\n",
    "    Row(12, \"Nitrogen oxides\", \"NOx\", \"ug/m^3\", 8, \"Ultraviolet fluorescence\"),\n",
    "    Row(14, \"Ozone\", \"O3\", \"ug/m^3\", 6, \"Ultraviolet fluorescence\"),\n",
    "    Row(20, \"Toluene\", \"TOL\", \"ug/m^3\", 59, \"Ultraviolet fluorescence\"),\n",
    "    Row(30, \"Benzene\", \"BEN\", \"ug/m^3\", 59, \"Id.\"),\n",
    "    Row(35, \"Ethylbenzene\", \"EBE\", \"ug/m^3\", 59, \"Id.\"),\n",
    "    Row(37, \"Mexaxylene\", \"MXY\", \"ug/m^3\", 59, \"Id.\"),\n",
    "    Row(38, \"Paraxylene\", \"PXY\", \"ug/m^3\", 59, \"Id.\"),\n",
    "    Row(39, \"Orthoxylene\", \"OXY\", \"ug/m^3\", 59, \"Id.\"),\n",
    "    Row(42, \"Total hydrocarbons (hexane)\", \"TCH\", \"ug/m^3\", 2, \"Ultraviolet fluorescence\"),\n",
    "    Row(43, \"Methane\", \"CH4\", \"ug/m^3\", 2, \"Id.\"),\n",
    "    Row(44, \"Non-methane hydrocarbons (hexane)\", \"NMHC\", \"ug/m^3\", 2, \"Id.\"),\n",
    "]\n",
    "magnitudesSchema = StructType([\n",
    "    StructField(\"magnitudeId\", IntegerType(),False),\n",
    "    StructField(\"magnitudeName\", StringType(),True),\n",
    "    StructField(\"formula\", StringType(),True),\n",
    "    StructField(\"unit\", StringType(),True),\n",
    "    StructField(\"techniqueId\", IntegerType(),True),\n",
    "    StructField(\"techniqueName\", StringType(),True)  \n",
    "])\n",
    "magnitudesDf = spark.createDataFrame(magnitudes,magnitudesSchema)\n",
    "magnitudesDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a Dataframe called `enrichedAqDF` combining `aqDF` and `magnitudesDF`, which displays all the columns in `aqDF`but replacing column `MAGNITUDE` by column `magnitudeName`available in `magnitudesDF`, and removing all pair columns from `H01`, `V01` to `H24`, `V24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|magnitudeId|       magnitudeName|\n",
      "+-----------+--------------------+\n",
      "|          1|     Sulphur dioxide|\n",
      "|          6|     Carbon monoxide|\n",
      "|          7|   Nitrogen monoxide|\n",
      "|          8|    Nitrogen dioxide|\n",
      "|          9|           Particles|\n",
      "|         10|           Particles|\n",
      "|         12|     Nitrogen oxides|\n",
      "|         14|               Ozone|\n",
      "|         20|             Toluene|\n",
      "|         30|             Benzene|\n",
      "|         35|        Ethylbenzene|\n",
      "|         37|          Mexaxylene|\n",
      "|         38|          Paraxylene|\n",
      "|         39|         Orthoxylene|\n",
      "|         42|Total hydrocarbon...|\n",
      "|         43|             Methane|\n",
      "|         44|Non-methane hydro...|\n",
      "+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "magnitudesDF = magnitudesDf.select(\"magnitudeId\", \"magnitudeName\")\n",
    "magnitudesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqDF = aqDF.join(magnitudesDF,aqDF.MAGNITUDE == magnitudesDF.magnitudeId,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqDF = aqDF.withColumnRenamed(\"magnitudeName\",\"MAGNITUDENAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------+-----------------+----+-----+---+--------------------+\n",
      "|PROVINCE|TOWN|STATION|SAMPLING_LOCATION|YEAR|MONTH|DAY|       MAGNITUDENAME|\n",
      "+--------+----+-------+-----------------+----+-----+---+--------------------+\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  1|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  2|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  3|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  4|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  5|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  6|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  7|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  8|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10|  9|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 10|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 11|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 12|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 13|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 14|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 15|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 16|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 17|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 18|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 19|Non-methane hydro...|\n",
      "|      28|  79|      8|    28079008_44_2|2019|   10| 20|Non-methane hydro...|\n",
      "+--------+----+-------+-----------------+----+-----+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aqDF = aqDF.drop(\"MAGNITUDE\",\"magnitudeId\",\"H01\",\"V01\",\"H02\",\"V02\",\"H03\",\"V03\",\"H04\",\"V04\",\"H05\",\"V05\",\"H06\",\"V06\",\"H07\",\n",
    "                \"V07\",\"H08\",\"V08\",\"H09\",\"V09\",\"H10\",\"V10\",\"H11\",\"V11\",\"H12\",\"V12\",\"H13\",\"V13\"\n",
    "                ,\"H14\",\"V14\",\"H15\",\"V15\",\"H16\",\"V16\",\"H17\",\"V17\",\"H18\",\"V18\",\"H19\",\"V19\",\"H20\",\n",
    "                \"V20\",\"H21\",\"V21\",\"H22\",\"V22\",\"H23\",\"V23\",\"H24\",\"V24\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------+--------------------+-----------------+----+-----+---+\n",
      "|PROVINCE|TOWN|STATION|       MAGNITUDENAME|SAMPLING_LOCATION|YEAR|MONTH|DAY|\n",
      "+--------+----+-------+--------------------+-----------------+----+-----+---+\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  1|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  2|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  3|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  4|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  5|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  6|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  7|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  8|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10|  9|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 10|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 11|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 12|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 13|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 14|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 15|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 16|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 17|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 18|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 19|\n",
      "|      28|  79|      8|Non-methane hydro...|    28079008_44_2|2019|   10| 20|\n",
      "+--------+----+-------+--------------------+-----------------+----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aqDF.select([\"PROVINCE\",\"TOWN\",\"STATION\",\"MAGNITUDENAME\",\"SAMPLING_LOCATION\",\"YEAR\",\"MONTH\",\"DAY\"]).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
